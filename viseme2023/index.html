<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ -->
    <title>Learning Audio-Driven Viseme Dynamics for 3D Face Animation</title>

    <!-- Bootstrap -->
    <!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css" rel="stylesheet"> -->
    <link href="./bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- jQuery (Bootstrap 的所有 JavaScript 插件都依赖 jQuery，所以必须放在前边) -->
    <script src="./jquery-3.5.1.min.js"></script>
    <!-- HTML5 shim 和 Respond.js 是为了让 IE8 支持 HTML5 元素和媒体查询（media queries）功能 -->
    <!-- 警告：通过 file:// 协议（就是直接将 html 页面拖拽到浏览器中）访问页面时 Respond.js 不起作用 -->
    <!--[if lt IE 9]>
      <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
    <![endif]-->
    <style>

        h1, h2 {
            font-family: Arial;
        } 
         
        h1 {
            font-size: 22pt; 
        }
        h2 {
            font-size: 16pt;
        }

        p {
            font-size: large;
            font-family: Arial;
        }

        .logo-title {
            font-family: Arial;
        }

        .thick {
            font-weight: bold;
        }

        h2 {
            font-weight: bolder;
        }

        .author-institute {
            margin-top: 10px;
            text-align: center;
            font-size: x-large;
            color: #333333;
            font-weight: bold;
        }

        .abstract {
            font-size: large;
            font-family: Arial;
        }

        .title {
            margin-top: 50px;
            color: #333333;
        }

        .title h1 {
            font-weight: bolder;
        }

        .authors ul {
            overflow: auto;
            margin-top: 30px;
            text-align: center;
        }

        li.author {
            list-style-type: none;
            float: center;
            padding-left: 10px;
            padding-right: 10px;
        }

        .author-name {
            font-size: large;
            color: #333333;
            margin: 0;
        }

        .author-email {
            font-size: medium;
            color: #666666;
        }

        .open-source {
            margin-top:30px;
            margin-bottom: 50px;
        }

        .open-source ul {
            overflow: auto;
            margin-top: 30px;
            padding-left: 15px;
        }

        .open-source li {
            list-style-type: None;
            float: left;
            width: 50%;
            text-align: center;
        }

        .open-source li a {
            display: block;
            width: 100%;
            font-size: x-large;
        }

        .open-source li .glyphicon {
            padding-right: 5px;
        }

        .clip {
            margin-bottom: 40px;
        }

    </style>
  </head>
  <body>

    <div class="row">
        <div class="col-md-3"></div>
        <div class="col-md-6">
            <div class="title">
                <h1 style="text-align:center">Learning Audio-Driven Viseme Dynamics for 3D Face Animation</h1>
                <!--   <h2 style="text-align:center">&nbsp;</h2>   Publication venue -->


                <div class="authors">
                    <ul>
                        <li class="author">
                            <p class="author-name">Linchao Bao, Haoxian Zhang, Yue Qian, Tangli Xue, Changhai Chen, Xuefei Zhe, Di Kang</p>
                        </li>
                    </ul>
                </div>

                <div class="author-institute">
                    <span><img src="figures/lablogo.png" alt="logo-AI-lab" width=120px></span>
                </div> 
                
                <div class="open-source">
                    <ul>
                        <li>
                            <a class="btn btn-info" target="_blank" href="https://arxiv.org/abs/2301.06059">
                                <span class="glyphicon glyphicon-book"></span>
                                <span>Paper</span>
                            </a>
                        </li>

                        <li>
                            <a class="btn btn-success" target="_blank" href="https://youtu.be/3tKtxYeVGbQ">
                                <span class="glyphicon glyphicon-film"></span>
                                <span>Supplementary Video</span>
                            </a>
                        </li>
                    </ul>
                </div>

                
                <div class="teaser figure">
                    <img src="./figures/teaser.png" alt="teaser" width="100%">
                </div>
            </div>
        </div>
    </div><!-- row -->

    <div class="row">
        <div class="col-md-3"></div>
        <div class="col-md-6">
            <h2 style="margin-top:50px;">Abstract</h2>
            <p class="abstract">
We present a novel audio-driven facial animation approach that can generate realistic lip-synchronized 3D facial animations from the input audio. 
Our approach learns viseme dynamics from speech videos, produces animator-friendly viseme curves, and supports multilingual speech inputs. 
The core of our approach is a novel parametric viseme fitting algorithm that utilizes phoneme priors to extract viseme parameters from speech videos. 
With the guidance of phonemes, the extracted viseme curves can better correlate with phonemes, thus more controllable and friendly to animators. 
To support multilingual speech inputs and generalizability to unseen voices, we take advantage of deep audio feature models pretrained on multiple languages to learn the mapping from audio to viseme curves. 
Our audio-to-curves mapping achieves state-of-the-art performance even when the input audio suffers from distortions of volume, pitch, speed, or noise. 
Lastly, a viseme scanning approach for acquiring high-fidelity viseme assets is presented for efficient speech animation production. 
We show that the predicted viseme curves can be applied to different viseme-rigged characters to yield various personalized animations with realistic and natural facial motions. 
Our approach is artist-friendly and can be easily integrated into typical animation production workflows including blendshape or bone based animation. 
            </p>
        </div>
    </div>

    <div class="row">
        <div class="col-md-3"></div>
        <div class="col-md-6">
            <div class="video">
                <h2>Video (containing audio)</h2>
<iframe id="player1" width="800" height="450" src="https://www.youtube.com/embed/3tKtxYeVGbQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
            
            <div class="video-controller">
                <button class="btn btn-lg btn-danger" id="btn-youtube-1">Youtube</button>
                <button class="btn btn-lg btn-info" id="btn-bilibili-1">Bilibili</button>
            </div>
        </div>
    </div>

		<br />

    <div class="row">
        <div class="col-md-3"></div>
        <div class="col-md-6">
            <div class="video">
                <h2>Contact</h2>
                <p>
                    If you have any question, please contact <a href="http://linchaobao.github.io/">Linchao Bao</a>.
                </p>
            </div>
        </div>
    </div>


    <div class="row">
        <div class="col-md-3"></div>
        <div class="col-md-6">
            <div class="video">
                <h2>Citation</h2>
<pre><code>@article{bao2023viseme,
  title={Learning Audio-Driven Viseme Dynamics for 3D Face Animation},
  author={Bao, Linchao and Zhang, Haoxian and Qian, Yue and Xue, Tangli and Chen, Changhai and Zhe, Xuefei and Kang, Di},
  journal={arXiv preprint arXiv:2301.06059},
  year={2023}
}
</code></pre>
            </div>
        </div>
    </div>

    <script>

$( document ).ready(function() {

    // resize video to adjust the width of content
    $('iframe').on("load", function() {
        //$(this).height($(this).contents().height());
        var w = $(this).parents(".video").width();
        var h = w * 315 / 560;
        console.log(w);
        console.log(h);
        $(this).width(w);
        $(this).height(h);
    });

    $('#player1').on("load", function() {
        // change source of videos
        $('#btn-youtube-1').click(function() {
            console.log('change to youtube src');
            $('#player1').attr("src", "https://www.youtube.com/embed/3tKtxYeVGbQ");
        });

        $('#btn-bilibili-1').click(function() {
            console.log('change to bilibili src');
            $('#player1').attr("src", "https://player.bilibili.com/player.html?aid=480270808&bvid=BV11T41127WB&cid=967025868&page=1");
        });
    });

});
         
    </script>

         
    <!-- 加载 Bootstrap 的所有 JavaScript 插件。你也可以根据需要只加载单个插件。 -->
    <script src="./bootstrap/js/bootstrap.min.js"></script>
  </body>
</html>
